{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-art-ucci/Fast-Stable-Diffusion-PT-Colab/blob/main/DreamBooth_r%C3%A1pido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEsNHTtVlbkV"
      },
      "source": [
        "# Treine seu modelo em DreamBooth Rápido! Um fork de colab de https://github.com/TheLastBen/fast-stable-diffusion, \n",
        "Durante o processo, não fique 5 minutos sem visitar esta página.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Bae3VP6UsE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Conectar ao Google Drive**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbKbx185zqlz"
      },
      "source": [
        "# Configurando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyvcqeiL65Tj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # Dependências\n",
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pld5ps87a1q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mParece que sua GPU não serve nesse momento')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl  \n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mFEITO !')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Baixando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3KHGKqyeJp9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "\n",
        "#@markdown - Pular esta célula se você está recarregando uma sessão anterior\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/\n",
        "\n",
        "Huggingface_Token = \"\" #@param {type:\"string\"}\n",
        "token=Huggingface_Token\n",
        "\n",
        "#@markdown (Garanta que aceitou os termos em https://huggingface.co/runwayml/stable-diffusion-v1-5)\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Ou\n",
        "\n",
        "CKPT_Path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Ou\n",
        "\n",
        "CKPT_Link = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Um link direto de arquivo CKPT, link de CKPT do huggingface ou um arquivo CKPT do Google Drive.\n",
        "#@markdown ---\n",
        "\n",
        "Compatiblity_Mode=\"\" #@param {type:\"boolean\"}\n",
        "#@markdown - Marcar apenas se estiver com erros de conversão.\n",
        "\n",
        "\n",
        "def downloadmodel():\n",
        "  token=Huggingface_Token\n",
        "  if token==\"\":\n",
        "      token=input(\"Digite seu token do huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "         print('\u001b[1;31mGaranta que aceitou os termos em https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n",
        "\n",
        "if CKPT_Path !=\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  if os.path.exists(str(CKPT_Path)):\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    with capture.capture_output() as cap:\n",
        "      if Compatiblity_Mode:\n",
        "        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "      else:           \n",
        "        !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py      \n",
        "    !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /content/stable-diffusion-v1-5\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mFEITO !')\n",
        "    else:\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      !rm -r /content/stable-diffusion-v1-5\n",
        "      while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mErro de conversão, verifique seu arquivo CKPT e tente novamente')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(CKPT_Path)):\n",
        "       print('\u001b[1;31mCaminho errado, use o explorador de arquivos do notebook na lateral esquerda e copie o caminho para o arquivo')\n",
        "       time.sleep(5)\n",
        "\n",
        "\n",
        "elif CKPT_Link !=\"\":   \n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5     \n",
        "    !gdown --fuzzy $CKPT_Link -O model.ckpt    \n",
        "    if os.path.exists('/content/model.ckpt'):\n",
        "      if os.path.getsize(\"/content/model.ckpt\") > 1810671599:\n",
        "        !mkdir /content/stable-diffusion-v1-5\n",
        "        with capture.capture_output() as cap: \n",
        "          if Compatiblity_Mode:\n",
        "            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "          else:           \n",
        "            !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py                \n",
        "        !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.ckpt --dump_path /content/stable-diffusion-v1-5\n",
        "        if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          print('\u001b[1;32mDONE !')\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm /content/v1-inference.yaml\n",
        "          !rm /content/model.ckpt\n",
        "        else:\n",
        "          if os.path.exists('/content/v1-inference.yaml'):\n",
        "            !rm /content/v1-inference.yaml\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm -r /content/stable-diffusion-v1-5\n",
        "          !rm /content/model.ckpt\n",
        "          while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mErro de conversão, verifique seu arquivo CKPT e tente novamente')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize('/content/model.ckpt') < 1810671599:\n",
        "           print('\u001b[1;31mLink errado, verifique se o link é válido')\n",
        "           time.sleep(5)\n",
        "else:\n",
        "  downloadmodel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1B299g-_VJo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "#@markdown #MÉTODO RÁPIDO\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Use_New_Fast_Method= \"Yes\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if Use_New_Fast_Method==\"Yes\":\n",
        "\n",
        "  def fdownloadmodel():\n",
        "    token=input(\"Inserir seu token dohuggingface :\")\n",
        "    %cd /content/\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "      !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "      !rm -r /content/stable-diffusion-v1-5/.git\n",
        "      %cd /content/    \n",
        "      clear_output()\n",
        "\n",
        "  MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "  PT=\"\"\n",
        "  With_Prior_Preservation = \"No\"\n",
        "  Captionned_instance_images = True\n",
        "  Save_class_images_to_gdrive = False\n",
        "  \n",
        "  #@markdown - Se você rodar o método antigo na célula abaixo, você vai precisar reiniciar esta célula. Mas não precisa subir as imagens de novo.\n",
        "  \n",
        "  Session_Name = \"\" #@param{type: 'string'}\n",
        "  while Session_Name==\"\":\n",
        "    print('\u001b[1;31mInput the Session Name:') \n",
        "    Session_Name=input('')\n",
        "  INSTANCE_NAME=Session_Name\n",
        "\n",
        "  #@markdown - Para continuar a partir de onde parou na última sessão, digite o nome da sessão: se ela existir, vai dar continuidade; caso contrário cria uma nova sessão.\n",
        "\n",
        "  WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "  OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "  SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "  INSTANCE_DIR=WORKSPACE+\"/Sessions/\"+Session_Name+\"/instance_images\"\n",
        "  MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "  if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "    print('\u001b[1;32mCarregando sessão sem modelo original, baixando modelo....')\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !rm -r '/content/stable-diffusion-v1-5'    \n",
        "      fdownloadmodel()\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mErro baixando o modelo, garanta que você aceitou os termos em https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "    else:\n",
        "      print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
        "\n",
        "  elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "    print('\u001b[1;32mSessão encontrada, carregando o modelo treinado ...')\n",
        "    %mkdir -p \"$OUTPUT_DIR\"\n",
        "    with capture.capture_output() as cap:\n",
        "      %cd /content\n",
        "      !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "    !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\"\n",
        "    if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      resume=True\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      clear_output()\n",
        "      print('\u001b[1;32msessão carregada.')\n",
        "    else:\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mErro de conversão, se o problema continuar, remova o arquivo CKPT da pasta da sessão atual.')\n",
        "\n",
        "\n",
        "  elif not os.path.exists(str(SESSION_DIR)):\n",
        "      %mkdir -p \"$INSTANCE_DIR\"\n",
        "      print('\u001b[1;32mCriando sessão...')\n",
        "      if not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "          !rm -r '/content/stable-diffusion-v1-5'\n",
        "        fdownloadmodel()\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;32msessão criada, Vá para a parte de subir imagens.')\n",
        "      else:\n",
        "        print('\u001b[1;31mErro baixando o modelo, garanta que você aceitou os termos em https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n",
        "      \n",
        "      #@markdown \n",
        "\n",
        "      #@markdown # O passo mais importante é garantir que o nome dos arquivos de imagens têm o mesmo nome que a instância que você está crioando. Exemplo:\n",
        "      #@markdown - Se você tem 30 fotos de você mesmo, renomeie todas de uma vez deixando o número diferente na frente de cada foto. Exemplo: minha instância é iccutram, os arquivos ficam : iccutram (1).jpg, iccutram (2).png ....etc. sobe as imagens e faz a mesma coisa para cada conjunto de imagens que você quer treinar.\n",
        "      #@markdown - Um exemplo : https://i.imgur.com/d2lD3rz.jpeg\n",
        "      \n",
        "else:\n",
        "  print('\u001b[1;32mOk, vá para a célula do Método Antigo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC4ukG60fgMy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown #Imagens para criar instância\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Rodar a célula para subir as imagens de instância.\n",
        "\n",
        "if Use_New_Fast_Method==\"Sim\":\n",
        "\n",
        "  Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "  #@markdown - Desmarcar essa caixa para manter instância de imagens atuais.\n",
        "\n",
        "\n",
        "  if Remove_existing_instance_images:\n",
        "    if os.path.exists(str(INSTANCE_DIR)):\n",
        "      !rm -r \"$INSTANCE_DIR\"\n",
        "\n",
        "  if not os.path.exists(str(INSTANCE_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "\n",
        "  IMAGES_FOLDER_OPTIONAL=\"\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "  #@markdown - Se você preferir especificar diretamente a pasta de imagens ao invés de subí-las, isso vai te ajudar a adicionars as imagens para as imagens instanciadas (se já existirem). Deixar DESMARCADO se for subir.\n",
        "\n",
        "  while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "    print('\u001b[1;31mA pasta de imagens não existe, use o navegador do notebook para copiar o caminho :')\n",
        "    IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "  if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "    with capture.capture_output() as cap:\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/.\" \"$INSTANCE_DIR\"\n",
        "      %cd \"$INSTANCE_DIR\"\n",
        "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "      %cd /content\n",
        "      if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"      \n",
        "    print('\u001b[1;32mFeito, pode ir para a célular de treinamento')\n",
        "\n",
        "  elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "\n",
        "    with capture.capture_output() as cap:\n",
        "      %cd \"$INSTANCE_DIR\"\n",
        "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "      %cd /content\n",
        "      if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"\n",
        "    print('\u001b[1;32mFeito, pode ir para a célular de treinamento')\n",
        "\n",
        "else:\n",
        "  print(('\u001b[1;31mMarcar o New_Fast_Method para Yes para usar esta célula'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaLtXBbPleBr"
      },
      "source": [
        "# Método Antigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pH1oP-7yBZm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "#@markdown #Preparando\n",
        "#@markdown ---\n",
        "\n",
        "try:\n",
        "  Use_New_Fast_Method\n",
        "except:\n",
        "  Use_New_Fast_Method=\"No\"\n",
        "\n",
        "if Use_New_Fast_Method==\"No\":\n",
        "\n",
        "  Training_Subject = \"Character\" #@param [\"Character\", \"Object\", \"Style\", \"Artist\", \"Movie\", \"TV Show\"] \n",
        "\n",
        "  With_Prior_Preservation = \"Yes\" #@param [\"Yes\", \"No\"] \n",
        "  #@markdown - With the prior reservation method, the results are better, you will either have to upload around 200 pictures of the class you're training (dog, person, car, house ...) or let Dreambooth generate them.\n",
        "\n",
        "  MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "\n",
        "  Captionned_instance_images = False #@param {type:\"boolean\"}\n",
        "\n",
        "  #@markdown - Use the keywords included in each instance images as unique instance prompt, this allows to train on multiple subjects at the same time, example : \n",
        "  #@markdown - An instance image named fat_dog_doginstancename_in_a_pool.jpg\n",
        "  #@markdown - another instance image named a_cat_catinstancename_in_the_woods.png\n",
        "  #@markdown - the unique training instance prompts would be : fat dog doginstancename in a pool, a cat doginstancename in the woods\n",
        "  #@markdown - at inference you can generate the dog by simply using doginstancename (a random unique identifier) or the cat by catinstancename\n",
        "\n",
        "  #@markdown - Also you can enhance the training of a simple subject by simply describing the image using keywords like : smiling, outdoor, sad, lether jacket ...etc\n",
        "\n",
        "  #@markdown - If you enable this feature, and want to train on multiple subjects, use the AUTOMATIC1111 colab to generate good quality 512x512 100-200 Class images for each subject (dog and a cat and a cow), then put them all in the same folder and entrer the folder's path in the cell below.\n",
        "\n",
        "  #@markdown - If you enable this feature, you must add an instance name and a subject type (dog, man, car) to all the images, separate keywords by an underscore (_).\n",
        "\n",
        "\n",
        "\n",
        "  SUBJECT_TYPE = \"\" #@param{type: 'string'}\n",
        "  while SUBJECT_TYPE==\"\":\n",
        "    SUBJECT_TYPE=input('Input the subject type:')\n",
        "\n",
        "  #@markdown - If you're training on a character or an object, the subject type would be : Man, Woman, Shirt, Car, Dog, Baby ...etc\n",
        "  #@markdown - If you're training on a Style, the subject type would be : impressionist, brutalist, abstract, use \"beautiful\" for a general style...etc\n",
        "  #@markdown - If you're training on a Movie/Show, the subject type would be : Action, Drama, Science-fiction, Comedy ...etc\n",
        "  #@markdown - If you're training on an Artist, the subject type would be : Painting, sketch, drawing, photography, art ...etc\n",
        "\n",
        "\n",
        "  INSTANCE_NAME= \"\" #@param{type: 'string'}\n",
        "  while INSTANCE_NAME==\"\":\n",
        "    INSTANCE_NAME=input('Input the instance name (identifier) :')\n",
        "\n",
        "  #@markdown - The instance is an identifier, choose a unique identifier unknown by stable diffusion. \n",
        "\n",
        "  INSTANCE_DIR_OPTIONAL=\"\" #@param{type: 'string'}\n",
        "  INSTANCE_DIR=INSTANCE_DIR_OPTIONAL\n",
        "  while INSTANCE_DIR_OPTIONAL!=\"\" and not os.path.exists(str(INSTANCE_DIR)):\n",
        "      INSTANCE_DIR=input('\u001b[1;31mThe instance folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "\n",
        "  #@markdown - If the number of instance pictures is large, it is preferable to specify directly the folder instead of uploading, leave EMPTY to upload.\n",
        "\n",
        "  CLASS_DIR=\"/content/data/\"+ SUBJECT_TYPE\n",
        "  Number_of_subject_images=200#@param{type: 'number'}\n",
        "  while Number_of_subject_images==None:\n",
        "      Number_of_subject_images=input('Input the number of subject images :')\n",
        "  SUBJECT_IMAGES=Number_of_subject_images\n",
        "\n",
        "  Save_class_images_to_gdrive = False #@param {type:\"boolean\"}\n",
        "  #@markdown - Save time in case you're training multiple instances of the same class\n",
        "\n",
        "  if Training_Subject==\"Character\" or Training_Subject==\"Object\":\n",
        "    PT=\"photo of \"+INSTANCE_NAME+\" \"+SUBJECT_TYPE\n",
        "    CPT=\"a photo of a \"+SUBJECT_TYPE+\", ultra detailed\"\n",
        "    if Captionned_instance_images:\n",
        "      PT=\"photo of\"\n",
        "  elif Training_Subject==\"Style\":\n",
        "    With_Prior_Preservation = \"No\"\n",
        "    PT=\"in the \"+SUBJECT_TYPE+\" style of \"+INSTANCE_NAME\n",
        "    if Captionned_instance_images:\n",
        "      PT=\"in the style of\"  \n",
        "  elif Training_Subject==\"Artist\":\n",
        "    With_Prior_Preservation = \"No\"\n",
        "    PT=SUBJECT_TYPE+\" By \"+INSTANCE_NAME\n",
        "    if Captionned_instance_images:\n",
        "      PT=\"by the artist\"  \n",
        "  elif Training_Subject==\"Movie\":\n",
        "    PT=\"from the \"+SUBJECT_TYPE+\" movie \"+ INSTANCE_NAME\n",
        "    CPT=\"still frame from \"+SUBJECT_TYPE+\" movie, ultra detailed, 4k uhd\"\n",
        "    if Captionned_instance_images:\n",
        "      PT=\"from the movie\"  \n",
        "  elif Training_Subject==\"TV Show\":\n",
        "    CPT=\"still frame from \"+SUBJECT_TYPE+\" tv show, ultra detailed, 4k uhd\"\n",
        "    PT=\"from the \"+SUBJECT_TYPE+\" tv show \"+ INSTANCE_NAME\n",
        "    if Captionned_instance_images:\n",
        "      PT=\"from the tv show\"    \n",
        "    \n",
        "  OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
        "\n",
        "  if INSTANCE_DIR_OPTIONAL==\"\":\n",
        "    INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
        "    !mkdir -p \"$INSTANCE_DIR\"\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd \"$INSTANCE_DIR\"\n",
        "    !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "    %cd /content\n",
        "  print('\u001b[1;32mOK')\n",
        "\n",
        "else:\n",
        "  print(('\u001b[1;31mSet the New_Fast_Method to No to use this cell'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LVCHYyYTIc61"
      },
      "outputs": [],
      "source": [
        "#@markdown ##[Optional] Upload or choose a folder of the class pictures (pictures of dogs if you're training on a dog), 200 is good, more is better, if you upload less than Number_of_subject_images, it will automatically generate the rest.\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "import shutil\n",
        "\n",
        "if Use_New_Fast_Method==\"No\":\n",
        "\n",
        "  if (With_Prior_Preservation=='No'):\n",
        "    print(\"\u001b[1;32mThis training method/subject doesn't require class images\")\n",
        "\n",
        "  else:\n",
        "    CLASS_DIR=\"\" #@param{type: 'string'}\n",
        "    if (CLASS_DIR !=\"\") and os.path.exists(str(CLASS_DIR)):\n",
        "      CLASS_DIR=CLASS_DIR\n",
        "    elif (CLASS_DIR !=\"\") and not os.path.exists(str(CLASS_DIR)):\n",
        "      CLASS_DIR=input('\u001b[1;31mThe folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "    elif (CLASS_DIR ==\"\"):\n",
        "      CLASS_DIR=\"/content/data/\"+ SUBJECT_TYPE\n",
        "      !mkdir -p \"data/$SUBJECT_TYPE\"\n",
        "      uploaded = files.upload()\n",
        "      for filename in uploaded.keys():\n",
        "        shutil.move(filename, CLASS_DIR)\n",
        "        clear_output()\n",
        "    print('\u001b[1;32mOK')\n",
        "    \n",
        "  with capture.capture_output() as cap:\n",
        "    if os.path.exists(str(CLASS_DIR)):\n",
        "      %cd \"$CLASS_DIR\"\n",
        "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "      %cd /content\n",
        "\n",
        "else:\n",
        "  print('\u001b[1;31mSet the New_Fast_Method to No to use this cell')\n",
        "\n",
        "#@markdown - To save time, if you specify a CLASS_DIR which is a folder that containes class images (eg: 200 pics of a dog), dreambooth will use this folder. \n",
        "#@markdown -Leave it empty if you want to upload\n",
        "\n",
        "#@markdown - Skip the cell if you want it to generate class (subject) images.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9QbkfAVYYU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Iniciar DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "if not Resume_Training and not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r '/content/stable-diffusion-v1-5'\n",
        "  print('\u001b[1;31mModelo original não foi encontrado, baixando....\u001b[0m')\n",
        "  fdownloadmodel()\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "     print('\u001b[1;32mModelo baixado, indo para treinamento...')\n",
        "  else:\n",
        "     print('\u001b[1;31mErro dbaixando o modelo, garante que aceitou os termos em https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n",
        "\n",
        "#@markdown  - Se o resultado não estiver satisfatótio, marca aqui, rode a célula novamente e o treinamento vai continuar de onde parou.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "\n",
        "Training_Steps=3000 #@param{type: 'number'}\n",
        "#@markdown - Passos Totais = Número de imagens instanciadas multiplicado por 100: se você usou 30 imagens colocar 3000 passos. Se não estiver contente com o resultado, cotninue por mais 500 passos, independente da quantidade de imagens.\n",
        "\n",
        "Seed=96576 #@param{type: 'number'}\n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "#@markdown  - fp16 oru metade da precisão significa menos qualidade mas é o dobro da velocidade.\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "  %cd /usr/local/lib/python3.7/dist-packages/diffusers/models\n",
        "  !wget -O attention.py https://raw.githubusercontent.com/huggingface/diffusers/main/src/diffusers/models/attention.py\n",
        "  !pip uninstall -q xformers\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mSobrescrever seu modelo treinado anterior?, se marcar \"yes\" vai treinar um novo modelo, se marcar \"no\" continua o treinamento do modelo anterior.  yes ou no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mContinuando Treinamento...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('\u001b[1;31mModelo anterior não encontrado, treinando um novo modelo...\u001b[0m') \n",
        "  MODELT_NAME=MODEL_NAME\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Mínimo de 200 passos entre cada intervalo.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Comece com intervalos médios de checkpoints para este passo.\n",
        "\n",
        "Caption=''\n",
        "if Captionned_instance_images:\n",
        "  Caption='--image_captions_filename'\n",
        "\n",
        "if With_Prior_Preservation=='No':\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --train_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --center_crop \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps \n",
        "\n",
        "else:\n",
        "\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --train_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --class_data_dir=\"$CLASS_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --instance_prompt=\"$PT\"\\\n",
        "    --class_prompt=\"$CPT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --center_crop \\\n",
        "    --max_train_steps=$Training_Steps \\\n",
        "    --num_class_images=$SUBJECT_IMAGES\n",
        "\n",
        "if Save_class_images_to_gdrive:\n",
        "  if os.path.exists(str(CLASS_DIR)):\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/Class_images'):\n",
        "      !mkdir /content/gdrive/MyDrive/Class_images\n",
        "    Class_gdir= '/content/gdrive/MyDrive/Class_images/'+SUBJECT_TYPE\n",
        "    if not os.path.exists(str(Class_gdir)):\n",
        "      !cp -r \"$CLASS_DIR\" /content/gdrive/MyDrive/Class_images\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Quase lá ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  if Use_New_Fast_Method==\"No\":\n",
        "    !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
        "  else:\n",
        "    !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  if Use_New_Fast_Method==\"No\":  \n",
        "    if os.path.exists('/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'):\n",
        "      print(\"\u001b[1;32mFEITO, o modelo CKPT está no seu Google Drive.\")\n",
        "    else:\n",
        "      print(\"\u001b[1;31mAlgo deu errado\")\n",
        "  else:\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      print(\"\u001b[1;32mFEITO, o modelo de CKPT está na psta dessa sessão no seu Google Drive.\")\n",
        "    else:\n",
        "      print(\"\u001b[1;31mAlgo deu errado\")\n",
        "    \n",
        "else:\n",
        "  print(\"\u001b[1;31mAlgo deu errado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehi1KKs-l-ZS"
      },
      "source": [
        "# Testar o Modelo Treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAZGngFcI8hq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "Update_repo = True #@param {type:\"boolean\"}\n",
        "\n",
        "INSTANCE__NAME=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Ou Session_Name, Deixar desmarcado se você pretende usar o modelo treinado atual.\n",
        "\n",
        "if INSTANCE__NAME!=\"\":\n",
        "  INSTANCET=INSTANCE__NAME\n",
        "\n",
        "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  INSTANCET=INSTANCE_NAME  \n",
        "  if Use_Custom_Path:\n",
        "    del INSTANCET\n",
        "except:\n",
        "  pass\n",
        "#@markdown - se marcado, uma caixa de entrada vai pedir o caminho completo para o modelo desejado.\n",
        "\n",
        "try:\n",
        "  Use_New_Fast_Method\n",
        "except:\n",
        "  Use_New_Fast_Method=\"\"\n",
        "\n",
        "try:\n",
        "  INSTANCET\n",
        "  if Use_New_Fast_Method==\"No\" or Use_New_Fast_Method==\"\":\n",
        "    path_to_trained_model='/content/gdrive/MyDrive/'+INSTANCET+'.ckpt'\n",
        "  else:\n",
        "    path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31m Parece que você não treinou performance durante essa sessão (tradução ruim) \u001b[1;32m ou você escolheu um caminho personalizado,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mO modelo não existe no seu Google Drive, use o navegador de arquivos para indicar o caminho : \")\n",
        "   path_to_trained_model=input()\n",
        "\n",
        "         \n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/gdrive/MyDrive/\n",
        "    %mkdir sd\n",
        "    %cd sd\n",
        "    !git clone https://github.com/CompVis/stable-diffusion\n",
        "    !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "    !mkdir -p cache/{huggingface,torch}\n",
        "    %cd /content/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/torch ../root/.cache/\n",
        "\n",
        "if Update_repo:\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.sh  \n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/paths.py\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py \n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m')\n",
        "  !git pull\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:  \n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion'):\n",
        "    !mkdir /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/openai/CLIP\n",
        "    !mv /content/gdrive/MyDrive/sd/stable-diffusion/src/CLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/clip\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/GFPGAN/gfpgan /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/salesforce/BLIP\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/BLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/blip\n",
        "    !git clone https://github.com/sczhou/CodeFormer\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/CodeFormer /content/gdrive/MyDrive/sd/stable-diffusion/src/codeformer\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/Real-ESRGAN/ /content/gdrive/MyDrive/sd/stable-diffusion/src/realesrgan\n",
        "    !git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "    !cp -r /content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/Hafiidz/latent-diffusion\n",
        "    !cp -r  /content/gdrive/MyDrive/sd/stable-diffusion/ldm /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/usr/local/lib/python3.7/dist-packages/gradio-3.4b3.dist-info'):\n",
        "    %cd /content/\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.1\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.2\n",
        "    %mv Dependencies_AUT.1 Dependencies_AUT.7z.001\n",
        "    %mv Dependencies_AUT.2 Dependencies_AUT.7z.002\n",
        "    !7z x Dependencies_AUT.7z.001\n",
        "    time.sleep(2)\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers-4.19.2.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers-0.3.0.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate-0.12.0.dist-info    \n",
        "    !cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "    !rm -r /content/usr\n",
        "    !rm Dependencies_AUT.7z.001\n",
        "    !rm Dependencies_AUT.7z.002\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/ldm/modules\n",
        "    if 'A100' in s:\n",
        "      !wget -O attention.py https://raw.githubusercontent.com/CompVis/stable-diffusion/main/ldm/modules/attention.py\n",
        "    else:\n",
        "      !wget -O attention.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "    \n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules\n",
        "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
        "  !sed -i 's@gpu_call).*@gpu_call) \\n        demo.queue(concurrency_count=111500)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/\n",
        "  !wget -O ui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/ui.py\n",
        "  !sed -i 's@css = \"\".*@with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:\\n        css = file.read()@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py  \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "  !wget -O style.css https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/style.css\n",
        "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css  \n",
        "  %cd /content\n",
        "\n",
        "\n",
        "Use_Gradio_Server = False #@param {type:\"boolean\"}\n",
        "#@markdown  - Apenas marque se estiver problemas ao se conectar ao servidor local.\n",
        "\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  !sed -i '1037s@.*@            self.server_name = server_name@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = server_port@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\" if self.local_url.startswith(\"https\") else \"http\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  clear_output()\n",
        "  \n",
        "else:\n",
        "  share=''\n",
        "\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "  !sed -i '1037s@.*@            self.server_name = \"{srv[8:]}\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = 443@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "  clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion/\n",
        "\n",
        "!python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --disable-safe-unpickle --ckpt \"$path_to_trained_model\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8lqbV-Dt1Mk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bbKbx185zqlz",
        "AaLtXBbPleBr"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}